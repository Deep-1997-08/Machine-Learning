{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cost function:\n",
    "    \n",
    "J(w) = $\\lambda$*$||w||^2$ + $1/n$*$\\sum_{i=1}^{n}$max(0, 1-$y_i(w.x_i + b)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is to force the magnitude of weights to get minimized - in order to maximize the worst margin\n",
    "\n",
    "$\\frac{1}{||w||^2}$\n",
    "\n",
    "This indeed means that hard margin SVM tries to minimize ∥w∥2. Due to the formulation of the SVM problem, the margin is 1/∥w∥. As such, minimizing the norm of w is geometrically equivalent to maximizing the margin. Exactly what we want!\n",
    "\n",
    "The second part is called \"Hing Loss\" and we use in the SOft margin SVM\n",
    "\n",
    "since if the training example lies outside the margin ξi will be zero and it will only be nonzero when training example falls into margin region, and since hinge loss is always nonnegative, it happens we can rephrase our problem as\n",
    "\n",
    "$max(0, 1-y_i(w.x_i + b))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if:\n",
    "\n",
    "- $y_i$*($w^Tx + b$) $\\geq$ 1:\n",
    "        The we dont have the hing loss and only want to minimize the maginitude of w\n",
    "        \n",
    "        \n",
    "- else:\n",
    "\n",
    "J(w) = $\\lambda$*$||w||^2$ + $1/n$*$\\sum_{i=1}^{n}$max(0, 1-$y_i(w.x_i + b)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if:\n",
    "- $y_i$*($w^Tx + b$) $\\geq$ 1:\n",
    "\n",
    "$\\frac{dJ}{dw_k}$ = $2\\lambda.w_k$\n",
    "        \n",
    "- else:\n",
    "\n",
    "$\\frac{dJ}{dw_k}$ = $2\\lambda w_k$ -$y_i.x_i$\n",
    "\n",
    "$\\frac{dJ}{db}$ = $-y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update rules: GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w = w - \\alpha.dw$\n",
    "\n",
    "$ b = b - \\alpha.db$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solving using Sequential least squares programing (SLSQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class SVM:\n",
    "    lr: float\n",
    "    max_iteration: int\n",
    "    lambda_param: float\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        self.w=np.ones(n_features)\n",
    "        self.b=0\n",
    "        \n",
    "        for _ in tqdm(range(self.max_iteration), colour='blue'):\n",
    "            for idx, X_ in enumerate(X):\n",
    "                condition =(y_[idx] - (np.dot(x_,self.w)+b)) >=1\n",
    "                if condition:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w)\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],X_))\n",
    "                    self.b-=sel.lr*(-y_[idx])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        pred=np.dot(X,sel.w)+self.b\n",
    "        return np.sign(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVM(lr=0.0001, max_iteration=500, lambda_param=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y =datasets.make_blobs(n_samples=1000,n_features=2, centers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/4sh3p6bs3z95dmh035hfn9wm0000gn/T/ipykernel_17432/1298606489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/q7/4sh3p6bs3z95dmh035hfn9wm0000gn/T/ipykernel_17432/4073847829.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain,yTrain= generateBatchBipolar("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, linearConstraint, BFGS, Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SoftMarginSVM:\n",
    "    C:float\n",
    "    \n",
    "    def dualSvm(self, gramXy, alpha):\n",
    "        return alpha.sum()-0.5*alpha.dot(alpha.dot(gramXy))\n",
    "    \n",
    "    def dualSVMderivative(self,gramXy, alpha):\n",
    "        return np.ones_like(len(alpha))-alpha.dot(gramXy)\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        N, n_features = X.shape\n",
    "        \n",
    "        xy=X*y[:,np.newaxis]\n",
    "        gramXy=np.matmul(xy,xy.T)\n",
    "        \n",
    "        # A=np.Vstack((-np.eye(N), np.eye(N)))\n",
    "        # B=np.concatinate((np.zeros(N),np.full(N*self.C)))\n",
    "        \n",
    "        alpha=np.ones(N)\n",
    "        bounds=bounds(np.zeros(N),np.full(N,self.C))\n",
    "        constraints = ({'type':'eq', 'fun':lambda a:-a.dot(y),\n",
    "                       'jac': lambda a:y})\n",
    "        \n",
    "        optimizer = minimize(fun=lambda a: -self.dealSvm(gramXy,alpha),\n",
    "                             jac=self.dualSVMderivative(gramXy, alpha), \n",
    "                             x0=alpha,\n",
    "                             method='SLSQP',\n",
    "                            constraints=constraints,\n",
    "                            bounds=bounds)\n",
    "        \n",
    "        self.alpha=optimizer.x\n",
    "        self.w = np.sum((self.alpha[:,np.newaxis])*Xy,axis=0)\n",
    "        \n",
    "        self.epsilon=1e-6\n",
    "        self.supportVectors= X[self.alpha>self.epsilon]\n",
    "        \n",
    "        signdist = np.matmul(self.supportVector,self.w)\n",
    "        mindist=np.argmin(sigdist)\n",
    "        support_lambda=y[self.alpha>epsilon]\n",
    "        \n",
    "        self.b=support_labels[mindist]-signdist[mindist]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= SoftMarginSVM(C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'bounds' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/4sh3p6bs3z95dmh035hfn9wm0000gn/T/ipykernel_17432/2489992722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/q7/4sh3p6bs3z95dmh035hfn9wm0000gn/T/ipykernel_17432/872675912.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         constraints = ({'type':'eq', 'fun':lambda a:-a.dot(y),\n\u001b[1;32m     24\u001b[0m                        'jac': lambda a:y})\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'bounds' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
